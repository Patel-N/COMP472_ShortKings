{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52604113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(\"ignore\") \n",
    "\n",
    "from matplotlib import test\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from collections import Counter\n",
    "from pretty_confusion_matrix import pp_matrix #pip install pretty_confusion_matrix\n",
    "\n",
    "import gensim.downloader as api\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "from fpdf import FPDF #pip install fpdf2 #pip install fpdf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e2d89",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994c7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "emotions = []\n",
    "comments = []\n",
    "\n",
    "commentsTrainVector = None\n",
    "commentsTestVector = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cdc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2\n",
    "emotionsGZIP = gzip.open(\"./goemotions.json.gz\", \"rb\")\n",
    "emotionsJSON = json.load(emotionsGZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c17801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPieChart(dict, dictName):\n",
    "    labels = []\n",
    "    values = []\n",
    "    for x,y in dict.items():\n",
    "        labels.append(x)\n",
    "        values.append(y)\n",
    "    plt.pie(values, labels=labels, autopct=lambda p:f'{p:.2f}%, {p*sum(values)/100 :.0f}')\n",
    "    plt.savefig(fname='./graphs/'+dictName+'.pdf', format='pdf')\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "426ad414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1.3\n",
    "for value in emotionsJSON:\n",
    "        emotions.append(value[1])\n",
    "        sentiments.append(value[2])\n",
    "        comments.append(value[0])\n",
    "\n",
    "createPieChart(Counter(emotions), 'emotions_with_values')\n",
    "createPieChart(Counter(sentiments), 'sentiments_with_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360d3f1",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f990a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "vectorizer = CountVectorizer()\n",
    "X  = vectorizer.fit(comments)\n",
    "print(\"Vocabulary size: \", len(X.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b873ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2\n",
    "comments_train, comments_test, sentiments_train, sentiments_test, emotions_train, emotions_test = train_test_split(comments, sentiments, emotions, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea451870",
   "metadata": {},
   "source": [
    "## 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11bcf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3\n",
    "vectorizer = CountVectorizer()\n",
    "commentsTrainVector = vectorizer.fit_transform(comments_train)\n",
    "commentsTestVector = vectorizer.transform(comments_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82dc48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getBaseClassifiersPredictions(classifier, commentsTrainVector, commentsTestVector, sentiments_train, emotions_train):\n",
    "\n",
    "    #emotions\n",
    "    classifier.fit(commentsTrainVector, emotions_train)\n",
    "    emotions_classifier = copy.deepcopy(classifier)\n",
    "    emotions_pred = classifier.predict(commentsTestVector)\n",
    "    #print(emotions_pred)\n",
    "\n",
    "    #sentiments\n",
    "    classifier.fit(commentsTrainVector, sentiments_train)\n",
    "    sentiments_classifier = copy.deepcopy(classifier)\n",
    "    sentiments_pred = classifier.predict(commentsTestVector)\n",
    "    #print(sentiments_pred)\n",
    "\n",
    "    return emotions_pred, sentiments_pred, emotions_classifier, sentiments_classifier\n",
    "\n",
    "def getGridSearchWithModelAndParams(model, params, cvCount, jobs, commentsTrainVector, commentsTestVector, sentiments_train, emotions_train):\n",
    "    #Setup GridSearch and hyperparams\n",
    "    tunedClassifier = GridSearchCV(model, params, cv=cvCount, n_jobs=jobs)\n",
    "    hyperparams = list(params.keys())\n",
    "    hyperparamsWithParams = ['param_' + paramInList for paramInList in hyperparams]\n",
    "    \n",
    "    #emotions\n",
    "    tunedClassifier.fit(commentsTrainVector, emotions_train)\n",
    "    emotions_tunedClassifier = copy.deepcopy(tunedClassifier)\n",
    "    emotions_cv_results = tunedClassifier.cv_results_\n",
    "    df = pd.DataFrame(emotions_cv_results)\n",
    "    \n",
    "    emotions_pred = tunedClassifier.predict(commentsTestVector)\n",
    "    \n",
    "    print(df[hyperparamsWithParams])\n",
    "    print(tunedClassifier.best_score_)\n",
    "    print(tunedClassifier.best_params_)\n",
    "    print(tunedClassifier.predict(commentsTestVector))\n",
    "\n",
    "    #sentiments\n",
    "    tunedClassifier.fit(commentsTrainVector, sentiments_train)\n",
    "    sentiments_tunedClassifier = copy.deepcopy(tunedClassifier)\n",
    "    sentiments_cv_results = tunedClassifier.cv_results_\n",
    "    df = pd.DataFrame(sentiments_cv_results)\n",
    "\n",
    "    sentiments_pred = tunedClassifier.predict(commentsTestVector)\n",
    "    \n",
    "    print(df[hyperparamsWithParams])\n",
    "    print(tunedClassifier.best_score_)\n",
    "    print(tunedClassifier.best_params_)\n",
    "    print(tunedClassifier.predict(commentsTestVector))\n",
    "\n",
    "    return emotions_pred, sentiments_pred, emotions_tunedClassifier, sentiments_tunedClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac1191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.1\n",
    "emotions_baseMNB_pred, sentiments_baseMNB_pred, emotions_baseMNB_classifier, sentiments_baseMNB_classifier = getBaseClassifiersPredictions(MultinomialNB(), commentsTrainVector, commentsTestVector, sentiments_train, emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17eca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.2\n",
    "emotions_baseDT_pred, sentiments_baseDT_pred, emotions_baseDT_classifier, sentiments_baseDT_classifier = getBaseClassifiersPredictions(DecisionTreeClassifier(random_state = 0), commentsTrainVector, commentsTestVector, sentiments_train, emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddcc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.3\n",
    "emotions_baseMLP_pred, sentiments_baseMLP_pred, emotions_baseMLP_classifier, sentiments_baseMLP_classifier = getBaseClassifiersPredictions(MLPClassifier(random_state = 0, max_iter=2), commentsTrainVector, commentsTestVector, sentiments_train, emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d12165",
   "metadata": {},
   "outputs": [],
   "source": [
    " #2.3.4\n",
    "mnb_classifier = MultinomialNB()\n",
    "mnb_params = {\n",
    "    'alpha': [0, 0.5, 1, 10]\n",
    "    }\n",
    "emotions_topMNB_pred, sentiments_topMNB_pred, emotions_topMNB_classifier, sentiments_topMNB_classifier = getGridSearchWithModelAndParams(mnb_classifier, mnb_params, 10, 2, commentsTrainVector, commentsTestVector, sentiments_train, emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c1d633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.5\n",
    "dt_classifier = DecisionTreeClassifier(random_state = 0)\n",
    "dt_params = {\n",
    "    'criterion': ['entropy'],\n",
    "    'max_depth': [400, 600],\n",
    "    'min_samples_split': [4,6,8]\n",
    "}\n",
    "emotions_topDT_pred, sentiments_topDT_pred, emotions_topDT_classifier, sentiments_topDT_classifier = getGridSearchWithModelAndParams(dt_classifier, dt_params, 5, 2, commentsTrainVector, commentsTestVector, sentiments_train, emotions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad18fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3.6\n",
    "mlp_classifier = MLPClassifier(random_state = 0)\n",
    "mlp_params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(10, 30), (8, 8, 8)],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'max_iter': [2]\n",
    "    }\n",
    "emotions_topMLP_pred, sentiments_topMLP_pred, emotions_topMLP_classifier, sentiments_topMLP_classifier = getGridSearchWithModelAndParams(mlp_classifier, mlp_params, 5, 2, commentsTrainVector, commentsTestVector, sentiments_train, emotions_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b0e108",
   "metadata": {},
   "source": [
    "## 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d11c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getNewNameFileInPrecisionFolder(fName, extension):\n",
    "    i = 0\n",
    "    fullFileName = \"./precision/\"+fName+\"_%s\"+extension\n",
    "    while os.path.exists( fullFileName % i):\n",
    "        i += 1\n",
    "\n",
    "    return fullFileName%i\n",
    "\n",
    "def generateConfusionMatrix(clf, y_test, y_pred, figureFileName):\n",
    "    #get confusion_matrix\n",
    "    cm =  confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    #Create graph\n",
    "    cmd = ConfusionMatrixDisplay( confusion_matrix = cm, display_labels= clf.classes_)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "    cmd.plot(cmap=plt.cm.Blues, ax= ax, xticks_rotation='vertical')\n",
    "\n",
    "    figurePath = getNewNameFileInPrecisionFolder('confusion_matrix_figures/'+figureFileName, '.png')\n",
    "    \n",
    "    #Save graph\n",
    "    cmd.figure_.savefig(figurePath)\n",
    "\n",
    "    return cm, figurePath\n",
    "\n",
    "def generateClassificationReport(clf, y_test, y_pred, reportFileName):\n",
    "    report = classification_report(y_test, y_pred, labels= clf.classes_)\n",
    "\n",
    "    #Create file\n",
    "    filePath = getNewNameFileInPrecisionFolder('classification_reports/'+reportFileName, '.txt')\n",
    "    fo = open(filePath, 'wb')\n",
    "    fo.write(str.encode(report))\n",
    "    fo.close()\n",
    "    return report, filePath\n",
    "\n",
    "\n",
    "def addImage(pdf, path):\n",
    "    cover = Image.open(path)\n",
    "    width, height = cover.size\n",
    "    width, height = float(width * 0.264583), float(height * 0.264583)\n",
    "    pdf.add_page(format=(width, height))\n",
    "    pdf.image(path, 0, 0, width, height)\n",
    "\n",
    "def createPrecisionReport(modelName=None, hyperParams=None, emotions_pred=None, sentiments_pred=None, emotions_classifier=None, sentiments_classifier=None, emotions_test= emotions_test, sentiments_test= sentiments_test):\n",
    "    \n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(family='Arial', size=14)\n",
    "    \n",
    "    #Description\n",
    "    pdf.multi_cell(0, 5,'Model: \\t'+modelName+'\\n')\n",
    "    pdf.multi_cell(0, 5,'HyperParams: \\n')\n",
    "    if hyperParams is not None:\n",
    "        pdf.multi_cell(0, 5,json.dumps(hyperParams, indent=4)+'\\n')\n",
    "    pdf.multi_cell(0, 5,'\\n')\n",
    "\n",
    "    #Emotions\n",
    "    cm_emotions, figurePath_emotions = generateConfusionMatrix(emotions_classifier, emotions_test, emotions_pred, modelName+'_emotions')\n",
    "    report_emotions, reportPath_emotions = generateClassificationReport(emotions_classifier, emotions_test, emotions_pred, modelName+'_emotions')\n",
    "\n",
    "    pdf.multi_cell(0, 5,'Classifications: Emotions\\n')\n",
    "    pdf.multi_cell(0, 5,'Confusion Matrix:\\n')\n",
    "    pdf.multi_cell(0, 5,'View Visual matrix at: ' + figurePath_emotions +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, np.array2string(cm_emotions)+'\\n')\n",
    "    pdf.multi_cell(0, 5,'Classsification Report:\\n')\n",
    "    pdf.multi_cell(0, 5,'View formatted classification report at: ' + reportPath_emotions +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, report_emotions+'\\n')\n",
    "    #Sentiments\n",
    "    pdf.add_page()\n",
    "    cm_sentiments, figurePath_sentiments = generateConfusionMatrix(sentiments_classifier, sentiments_test, sentiments_pred, modelName+'_sentiments')\n",
    "    report_sentiments, reportPath_sentiments = generateClassificationReport(sentiments_classifier, sentiments_test, sentiments_pred, modelName+'_sentiments')\n",
    "\n",
    "    pdf.multi_cell(0, 5,'Classifications: Emotions\\n')\n",
    "    pdf.multi_cell(0, 5,'Confusion Matrix:\\n')\n",
    "    pdf.multi_cell(0, 5,'View Visual matrix at: ' + figurePath_sentiments +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, np.array2string(cm_sentiments)+'\\n')\n",
    "    pdf.multi_cell(0, 5,'Classsification Report:\\n')\n",
    "    pdf.multi_cell(0, 5,'View formatted classification report at: ' + reportPath_sentiments +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, report_sentiments+'\\n')\n",
    "    filePath = getNewNameFileInPrecisionFolder(modelName, '.pdf')\n",
    "\n",
    "    #Create file\n",
    "    pdf.output(filePath, 'F')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2069c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaseMNB\n",
    "createPrecisionReport(modelName = \"base_MultinomialNB\", emotions_pred = emotions_baseMNB_pred, sentiments_pred = sentiments_baseMNB_pred, emotions_classifier = emotions_baseMNB_classifier, sentiments_classifier = sentiments_baseMNB_classifier)\n",
    "\n",
    "#BaseDT\n",
    "createPrecisionReport(modelName = \"base_DecisionTree\", emotions_pred = emotions_baseDT_pred, sentiments_pred = sentiments_baseDT_pred, emotions_classifier = emotions_baseDT_classifier, sentiments_classifier = sentiments_baseDT_classifier)\n",
    "\n",
    "#BaseMLP\n",
    "createPrecisionReport(modelName = \"base_MLP\", emotions_pred = emotions_baseMLP_pred, sentiments_pred = sentiments_baseMLP_pred, emotions_classifier = emotions_baseMLP_classifier, sentiments_classifier = sentiments_baseMLP_classifier)\n",
    "\n",
    "#TopMNB\n",
    "createPrecisionReport(modelName = \"top_MultinomialNB\", hyperParams=mnb_params, emotions_pred = emotions_topMNB_pred, sentiments_pred = sentiments_topMNB_pred, emotions_classifier = emotions_topMNB_classifier, sentiments_classifier = sentiments_topMNB_classifier)\n",
    "\n",
    "#TopDT\n",
    "createPrecisionReport(modelName = \"top_DecisionTree\", hyperParams=dt_params, emotions_pred = emotions_topDT_pred, sentiments_pred = sentiments_topDT_pred, emotions_classifier = emotions_topDT_classifier, sentiments_classifier = sentiments_topDT_classifier)\n",
    "\n",
    "#TopMLP\n",
    "createPrecisionReport(modelName = \"top_MLP\", hyperParams=mlp_params, emotions_pred = emotions_topMLP_pred, sentiments_pred = sentiments_topMLP_pred, emotions_classifier = emotions_topMLP_classifier, sentiments_classifier = sentiments_topMLP_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03443e",
   "metadata": {},
   "source": [
    "# 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d95549",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train_2_5, comments_test_2_5, sentiments_train_2_5, sentiments_test_2_5, emotions_train_2_5, emotions_test_2_5 = train_test_split(comments, sentiments, emotions, test_size=0.6, random_state=0)\n",
    "\n",
    "commentsTrainVector_2_5 = vectorizer.fit_transform(comments_train_2_5)\n",
    "commentsTestVector_2_5 = vectorizer.transform(comments_test_2_5)\n",
    "\n",
    "#2.3.1\n",
    "emotions_baseMNB_pred_2_5, sentiments_baseMNB_pred_2_5, emotions_baseMNB_classifier_2_5, sentiments_baseMNB_classifier_2_5 = getBaseClassifiersPredictions(MultinomialNB(), commentsTrainVector_2_5, commentsTestVector_2_5, sentiments_train_2_5, emotions_train_2_5)\n",
    "\n",
    "#2.3.2\n",
    "emotions_baseDT_pred_2_5, sentiments_baseDT_pred_2_5, emotions_baseDT_classifier_2_5, sentiments_baseDT_classifier_2_5 = getBaseClassifiersPredictions(DecisionTreeClassifier(random_state = 0), commentsTrainVector_2_5, commentsTestVector_2_5, sentiments_train_2_5, emotions_train_2_5)\n",
    "\n",
    "#2.3.3\n",
    "emotions_baseMLP_pred_2_5, sentiments_baseMLP_pred_2_5, emotions_baseMLP_classifier_2_5, sentiments_baseMLP_classifier_2_5 = getBaseClassifiersPredictions(MLPClassifier(max_iter=2,random_state = 0), commentsTrainVector_2_5, commentsTestVector_2_5, sentiments_train_2_5, emotions_train_2_5)\n",
    "\n",
    " #2.3.4\n",
    "mnb_classifier = MultinomialNB()\n",
    "emotions_topMNB_pred_2_5, sentiments_topMNB_pred_2_5, emotions_topMNB_classifier_2_5, sentiments_topMNB_classifier_2_5 = getGridSearchWithModelAndParams(mnb_classifier, mnb_params, 10, 2, commentsTrainVector_2_5, commentsTestVector_2_5, sentiments_train_2_5, emotions_train_2_5)\n",
    "\n",
    "#2.3.5\n",
    "dt_classifier = DecisionTreeClassifier(random_state = 0)\n",
    "emotions_topDT_pred_2_5, sentiments_topDT_pred_2_5, emotions_topDT_classifier_2_5, sentiments_topDT_classifier_2_5 = getGridSearchWithModelAndParams(dt_classifier, dt_params, 5, 2, commentsTrainVector_2_5, commentsTestVector_2_5, sentiments_train_2_5, emotions_train_2_5)\n",
    "\n",
    "#2.3.6\n",
    "mlp_classifier = MLPClassifier(random_state = 0)\n",
    "emotions_topMLP_pred_2_5, sentiments_topMLP_pred_2_5, emotions_topMLP_classifier_2_5, sentiments_topMLP_classifier_2_5 = getGridSearchWithModelAndParams(mlp_classifier, mlp_params, 5, 2, commentsTrainVector_2_5, commentsTestVector_2_5, sentiments_train_2_5, emotions_train_2_5)\n",
    "\n",
    "#BaseMNB\n",
    "createPrecisionReport(modelName = \"base_MultinomialNB_2.5\", emotions_pred = emotions_baseMNB_pred_2_5, sentiments_pred = sentiments_baseMNB_pred, emotions_classifier = emotions_baseMNB_classifier_2_5, sentiments_classifier = sentiments_baseMNB_classifier_2_5, emotions_test= emotions_test_2_5, sentiments_test= sentiments_test_2_5)\n",
    "\n",
    "#BaseDT\n",
    "createPrecisionReport(modelName = \"base_DecisionTree_2.5\", emotions_pred = emotions_baseDT_pred_2_5, sentiments_pred = sentiments_baseDT_pred_2_5, emotions_classifier = emotions_baseDT_classifier_2_5, sentiments_classifier = sentiments_baseDT_classifier_2_5, emotions_test= emotions_test_2_5, sentiments_test= sentiments_test_2_5)\n",
    "\n",
    "#BaseMLP\n",
    "createPrecisionReport(modelName = \"base_MLP_2.5\", emotions_pred = emotions_baseMLP_pred_2_5, sentiments_pred = sentiments_baseMLP_pred_2_5, emotions_classifier = emotions_baseMLP_classifier, sentiments_classifier = sentiments_baseMLP_classifier_2_5, emotions_test= emotions_test_2_5, sentiments_test= sentiments_test_2_5)\n",
    "\n",
    "#TopMNB\n",
    "createPrecisionReport(modelName = \"top_MultinomialNB_2.5\", hyperParams=mnb_params, emotions_pred = emotions_topMNB_pred_2_5, sentiments_pred = sentiments_topMNB_pred_2_5, emotions_classifier = emotions_topMNB_classifier_2_5, sentiments_classifier = sentiments_topMNB_classifier_2_5, emotions_test= emotions_test_2_5, sentiments_test= sentiments_test_2_5)\n",
    "\n",
    "#TopDT\n",
    "createPrecisionReport(modelName = \"top_DecisionTree_2.5\", hyperParams=dt_params, emotions_pred = emotions_topDT_pred_2_5, sentiments_pred = sentiments_topDT_pred_2_5, emotions_classifier = emotions_topDT_classifier_2_5, sentiments_classifier = sentiments_topDT_classifier_2_5, emotions_test= emotions_test_2_5, sentiments_test= sentiments_test_2_5)\n",
    "\n",
    "#TopMLP\n",
    "createPrecisionReport(modelName = \"top_MLP_2.5\", hyperParams=mlp_params, emotions_pred = emotions_topMLP_pred_2_5, sentiments_pred = sentiments_topMLP_pred_2_5, emotions_classifier = emotions_topMLP_classifier_2_5, sentiments_classifier = sentiments_topMLP_classifier_2_5, emotions_test= emotions_test_2_5, sentiments_test= sentiments_test_2_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c97fa8",
   "metadata": {},
   "source": [
    "3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afae098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a8efa",
   "metadata": {},
   "source": [
    "3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1902db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count:  14761142110\n"
     ]
    }
   ],
   "source": [
    "#3.2\n",
    "tokenized_comments = []\n",
    "totalToken = 0\n",
    "\n",
    "for comment in comments:\n",
    "    tokenized_comments.append(word_tokenize(comment))\n",
    "    totalToken = totalToken + len(tokenized_comments)\n",
    "\n",
    "print('Total token count: ', totalToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e03cc",
   "metadata": {},
   "source": [
    "3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d01c634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7745063827339175\n"
     ]
    }
   ],
   "source": [
    "avgs = []\n",
    "w2vec_dict = dict(zip(model.key_to_index.keys(),  model.vectors))\n",
    "hits = 0\n",
    "totalWords = 0\n",
    "for soloTokenComment in tokenized_comments:\n",
    "    commentVector = []\n",
    "    foundCounter = 0\n",
    "    commentVector = [0 for i in range(300)]\n",
    "    for token in soloTokenComment:\n",
    "        totalWords = totalWords + 1\n",
    "        if token in w2vec_dict:\n",
    "            hits = hits + 1\n",
    "            foundCounter = foundCounter + 1\n",
    "            commentVector = [x+y for x,y in zip(commentVector,w2vec_dict[token])]\n",
    "    \n",
    "    if foundCounter != 0: \n",
    "        averagedCommentVector = [colVal / foundCounter for colVal in commentVector]\n",
    "    \n",
    "    avgs.append(averagedCommentVector)\n",
    "\n",
    "print(hits / totalWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514206a6",
   "metadata": {},
   "source": [
    "3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2598dbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train, comments_test, sentiments_train, sentiments_test, emotions_train, emotions_test = train_test_split(avgs, sentiments, emotions, test_size=0.2, random_state=0)\n",
    "clf_S = MLPClassifier().fit(comments_train, sentiments_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e2b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlp_3classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=  (10, 30),\n",
    "    activation= 'tanh',\n",
    "    solver =  'adam',\n",
    "    max_iter = 2,\n",
    "    random_state = 0)\n",
    "\n",
    "mlp_3params = {\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'hidden_layer_sizes': [(10, 30), (8, 8, 8)],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'max_iter': [2]\n",
    "    }\n",
    "clf_TOPS = mlp_3classifier.fit(comments_train, sentiments_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc02b82",
   "metadata": {},
   "source": [
    "3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3627e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateConfusionMatrixEmbeddingsNoPrint(clf, y_test, y_pred, figureFileName):\n",
    "    #get confusion_matrix\n",
    "    cm =  confusion_matrix(y_test,y_pred)\n",
    "    \n",
    "    #Create graph\n",
    "    cmd = ConfusionMatrixDisplay( confusion_matrix = cm)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "    cmd.plot(cmap=plt.cm.Blues, ax= ax, xticks_rotation='vertical')\n",
    "\n",
    "    figurePath = getNewNameFileInPrecisionFolder('confusion_matrix_figures/'+figureFileName, '.png')\n",
    "    \n",
    "    #Save graph\n",
    "    cmd.figure_.savefig(figurePath)\n",
    "\n",
    "    return cm, figurePath\n",
    "\n",
    "def generateClassificationReportEmbeddingsNoPrint(clf, y_test, y_pred, reportFileName):\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    #Create file\n",
    "    filePath = getNewNameFileInPrecisionFolder('classification_reports/'+reportFileName, '.txt')\n",
    "    fo = open(filePath, 'wb')\n",
    "    fo.write(str.encode(report))\n",
    "    fo.close()\n",
    "    return report, filePath\n",
    "\n",
    "\n",
    "def createPrecisionReportNoPrint(modelName=None, hyperParams=None, emotions_pred=None, sentiments_pred=None, emotions_classifier=None, sentiments_classifier=None, emotions_test= emotions_test, sentiments_test= sentiments_test):\n",
    "    \n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(family='Arial', size=14)\n",
    "    \n",
    "    #Description\n",
    "    pdf.multi_cell(0, 5,'Model: \\t'+modelName+'\\n')\n",
    "    pdf.multi_cell(0, 5,'HyperParams: \\n')\n",
    "    if hyperParams is not None:\n",
    "        pdf.multi_cell(0, 5,json.dumps(hyperParams, indent=4)+'\\n')\n",
    "    pdf.multi_cell(0, 5,'\\n')\n",
    "\n",
    "    #Emotions\n",
    "    cm_emotions, figurePath_emotions = generateConfusionMatrixEmbeddingsNoPrint(emotions_classifier, emotions_test, emotions_pred, modelName+'_emotions')\n",
    "    report_emotions, reportPath_emotions = generateClassificationReportEmbeddingsNoPrint(emotions_classifier, emotions_test, emotions_pred, modelName+'_emotions')\n",
    "\n",
    "    pdf.multi_cell(0, 5,'Classifications: Emotions\\n')\n",
    "    pdf.multi_cell(0, 5,'Confusion Matrix:\\n')\n",
    "    pdf.multi_cell(0, 5,'View Visual matrix at: ' + figurePath_emotions +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, np.array2string(cm_emotions)+'\\n')\n",
    "    pdf.multi_cell(0, 5,'Classsification Report:\\n')\n",
    "    pdf.multi_cell(0, 5,'View formatted classification report at: ' + reportPath_emotions +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, report_emotions+'\\n')\n",
    "    #Sentiments\n",
    "    pdf.add_page()\n",
    "    cm_sentiments, figurePath_sentiments = generateConfusionMatrixEmbeddingsNoPrint(sentiments_classifier, sentiments_test, sentiments_pred, modelName+'_sentiments')\n",
    "    report_sentiments, reportPath_sentiments = generateClassificationReportEmbeddingsNoPrint(sentiments_classifier, sentiments_test, sentiments_pred, modelName+'_sentiments')\n",
    "\n",
    "    pdf.multi_cell(0, 5,'Classifications: Emotions\\n')\n",
    "    pdf.multi_cell(0, 5,'Confusion Matrix:\\n')\n",
    "    pdf.multi_cell(0, 5,'View Visual matrix at: ' + figurePath_sentiments +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, np.array2string(cm_sentiments)+'\\n')\n",
    "    pdf.multi_cell(0, 5,'Classsification Report:\\n')\n",
    "    pdf.multi_cell(0, 5,'View formatted classification report at: ' + reportPath_sentiments +'\\n', align='L')\n",
    "    pdf.multi_cell(0, 5, report_sentiments+'\\n')\n",
    "    filePath = getNewNameFileInPrecisionFolder(modelName, '.pdf')\n",
    "\n",
    "    #Create file\n",
    "    pdf.output(filePath, 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2dc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaseMLP\n",
    "\n",
    "\n",
    "emotions_baseMLP_pred_3_4, sentiments_baseMLP_pred_3_4, emotions_baseMLP_classifier_3_4, sentiments_baseMLP_classifier_3_4 = getBaseClassifiersPredictions(clf_S, comments_train, comments_test, sentiments_train, emotions_train)\n",
    "emotions_topMLP_pred_3_5, sentiments_topMLP_pred_3_5, emotions_topMLP_classifier_3_5, sentiments_topMLP_classifier_3_5 = getGridSearchWithModelAndParams(clf_TOPS, mlp_3params, 5, 2, comments_train, comments_test, sentiments_train, emotions_train)\n",
    "\n",
    "\n",
    "createPrecisionReportNoPrint(modelName = \"base_MLP_3.4\", emotions_pred = emotions_baseMLP_pred_3_4, sentiments_pred = sentiments_baseMLP_pred_3_4, emotions_classifier = emotions_baseMLP_classifier, sentiments_classifier = sentiments_baseMLP_classifier_3_4, emotions_test= emotions_test, sentiments_test= sentiments_test)\n",
    "createPrecisionReportNoPrint(modelName = \"top_MLP_3.5\", hyperParams=mlp_3params, emotions_pred = emotions_topMLP_pred_3_5, sentiments_pred = sentiments_topMLP_pred_3_5, emotions_classifier = emotions_topMLP_classifier_3_5, sentiments_classifier = sentiments_topMLP_classifier_3_5, emotions_test= emotions_test, sentiments_test= sentiments_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0ec3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect model/corpus name",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w2v_model \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mbrown.embedding\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\downloader.py:492\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    490\u001b[0m file_name \u001b[39m=\u001b[39m _get_filename(name)\n\u001b[0;32m    491\u001b[0m \u001b[39mif\u001b[39;00m file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIncorrect model/corpus name\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    493\u001b[0m folder_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(BASE_DIR, name)\n\u001b[0;32m    494\u001b[0m path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_dir, file_name)\n",
      "\u001b[1;31mValueError\u001b[0m: Incorrect model/corpus name"
     ]
    }
   ],
   "source": [
    "w2v_model = api.load('‘GoogleNews-vectors-negative300')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41955ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wiki_avgs = []\n",
    "wiki_w2vec_dict = dict(zip(w2v_model.key_to_index.keys(),  w2v_model.vectors))\n",
    "for soloTokenComment in tokenized_comments:\n",
    "    commentVector = []\n",
    "    foundCounter = 0\n",
    "    commentVector = [0 for i in range(300)]\n",
    "    for token in soloTokenComment:\n",
    "        if token in wiki_w2vec_dict:\n",
    "            foundCounter = foundCounter + 1\n",
    "            commentVector = [x+y for x,y in zip(commentVector,wiki_w2vec_dict[token])]\n",
    "    \n",
    "    if foundCounter != 0: \n",
    "        averagedCommentVector = [colVal / foundCounter for colVal in commentVector]\n",
    "    \n",
    "    wiki_avgs.append(averagedCommentVector)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e038ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train, comments_test, sentiments_train, sentiments_test, emotions_train, emotions_test = train_test_split(wiki_avgs, sentiments, emotions, test_size=0.2, random_state=0)\n",
    "wiki = MLPClassifier(\n",
    "    hidden_layer_sizes=  (10, 30),\n",
    "    activation= 'tanh',\n",
    "    solver =  'adam',\n",
    "    max_iter = 2,\n",
    "    random_state = 0).fit(comments_train, sentiments_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7101ca937a6cefa303d920fd1335fe82956cc294edbf5f7bc268a5a56c54bb64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
